<p align="center">
  <a href="#"><img src="assets/bangla_clip_2.PNG" alt="bangla clip"></a>
</p>
<p align="center">
    <em>CLIP (Contrastive Languageâ€“Image Pre-training) training code for Bangla.</em>
</p>
<p align="center">
    <em>Live Demo: </em> <a href="https://huggingface.co/spaces/zabir-nabil/bangla-clip">HuggingFace Space</>
</p>

---

#### Installation

* `python >= 3.9`
* `pip install -r requirements.txt`


### Bangla CLIP

<p align="center">
  <a href="#"><img src="assets/clip_bangla.png" alt="bangla clip"></a>
</p>

The model consists of an EfficientNet / ResNet image encoder and a BERT text encoder and was trained on multiple datasets from Bangla image-text domain. To start training,

```console
python train_clip_bangla.py
```
---


### Image Search Demo with Bangla CLIP

 * *Search App Code:* [bangla-image-search](https://github.com/zabir-nabil/bangla-image-search)


